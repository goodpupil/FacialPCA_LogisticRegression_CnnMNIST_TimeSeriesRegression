{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mnist import MNIST\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mndata = MNIST('./data')\n",
    "mndata.gz = True\n",
    "train_images, train_labels = mndata.load_training()\n",
    "train_mod_labels = pd.get_dummies(train_labels).to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images, test_labels = mndata.load_testing()\n",
    "test_labels = np.array(test_labels)\n",
    "test_mod_labels = pd.get_dummies(test_labels).to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-layer perceptron using Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing library and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural network with 2 hidden layers, 1 dropout layer and relu, sigmoid, relu activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(Dense(16, input_dim=len(train_images[0]), activation='relu'))\n",
    "model1.add(Dense(1000, activation='sigmoid'))\n",
    "model1.add(Dropout(0.25))\n",
    "model1.add(Dense(1000, activation='relu'))\n",
    "model1.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 5s 87us/sample - loss: 0.5652 - accuracy: 0.8213\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 0.2287 - accuracy: 0.9291\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 0.1822 - accuracy: 0.9435\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.1561 - accuracy: 0.9510\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 0.1402 - accuracy: 0.9556\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 0.1268 - accuracy: 0.9604\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 0.1155 - accuracy: 0.9627\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 0.1096 - accuracy: 0.9652\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 0.1040 - accuracy: 0.9664\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.0995 - accuracy: 0.9679\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 4s 69us/sample - loss: 0.0928 - accuracy: 0.9701\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 0.0890 - accuracy: 0.9709\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.0862 - accuracy: 0.9717\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.0830 - accuracy: 0.9727\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 0.0775 - accuracy: 0.9745\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 4s 69us/sample - loss: 0.0771 - accuracy: 0.9744\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 0.0716 - accuracy: 0.9766\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.0674 - accuracy: 0.9774\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 0.0648 - accuracy: 0.9776\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.0676 - accuracy: 0.9772\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f37c05aba20>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(np.array(train_images), train_mod_labels, epochs=20, batch_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model1.predict(np.array(test_images))\n",
    "pred1 = []\n",
    "for i in range(len(y_pred)):\n",
    "    pred1.append(np.argmax(y_pred[i], axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy and classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       980\n",
      "           1       0.98      0.99      0.98      1135\n",
      "           2       0.95      0.97      0.96      1032\n",
      "           3       0.95      0.96      0.96      1010\n",
      "           4       0.97      0.97      0.97       982\n",
      "           5       0.96      0.96      0.96       892\n",
      "           6       0.96      0.98      0.97       958\n",
      "           7       0.97      0.97      0.97      1028\n",
      "           8       0.97      0.94      0.96       974\n",
      "           9       0.97      0.95      0.96      1009\n",
      "\n",
      "    accuracy                           0.97     10000\n",
      "   macro avg       0.97      0.97      0.97     10000\n",
      "weighted avg       0.97      0.97      0.97     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_labels, pred1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 962    1    1    4    0    2    5    2    3    0]\n",
      " [   0 1121    3    1    0    1    6    1    2    0]\n",
      " [   3    2 1004    7    5    1    2    5    3    0]\n",
      " [   0    1   15  974    0    5    0    7    2    6]\n",
      " [   1    1    3    0  949    1    9    2    1   15]\n",
      " [   1    0    1   14    2  855    7    3    5    4]\n",
      " [   6    3    3    1    4    6  935    0    0    0]\n",
      " [   0    8   12    4    0    0    1  995    3    5]\n",
      " [   7    2   11   13    4    9    6    7  913    2]\n",
      " [   1    6    0   11   16    8    1    6    5  955]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(test_labels, pred1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural network with 2 hidden layers and sigmoid, tanh, relu activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Dense(100, input_dim=len(train_images[0]), activation='sigmoid'))\n",
    "model2.add(Dense(100, activation='tanh'))\n",
    "model2.add(Dense(100, activation='relu'))\n",
    "model2.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/40\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 0.7982 - accuracy: 0.7768\n",
      "Epoch 2/40\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.3421 - accuracy: 0.8975\n",
      "Epoch 3/40\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.2762 - accuracy: 0.9151\n",
      "Epoch 4/40\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.2350 - accuracy: 0.9277\n",
      "Epoch 5/40\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.2165 - accuracy: 0.9336\n",
      "Epoch 6/40\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.1941 - accuracy: 0.9401\n",
      "Epoch 7/40\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.1805 - accuracy: 0.9441\n",
      "Epoch 8/40\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.1666 - accuracy: 0.9492\n",
      "Epoch 9/40\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.1550 - accuracy: 0.9524\n",
      "Epoch 10/40\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.1487 - accuracy: 0.9533\n",
      "Epoch 11/40\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.1438 - accuracy: 0.9554\n",
      "Epoch 12/40\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.1407 - accuracy: 0.9560\n",
      "Epoch 13/40\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.1330 - accuracy: 0.9578\n",
      "Epoch 14/40\n",
      "60000/60000 [==============================] - 1s 14us/sample - loss: 0.1243 - accuracy: 0.9614\n",
      "Epoch 15/40\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.1232 - accuracy: 0.9613\n",
      "Epoch 16/40\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.1160 - accuracy: 0.9640\n",
      "Epoch 17/40\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.1101 - accuracy: 0.9659\n",
      "Epoch 18/40\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.1092 - accuracy: 0.9653\n",
      "Epoch 19/40\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.1041 - accuracy: 0.9679\n",
      "Epoch 20/40\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 0.1063 - accuracy: 0.9669\n",
      "Epoch 21/40\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.1013 - accuracy: 0.9687\n",
      "Epoch 22/40\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0998 - accuracy: 0.9687\n",
      "Epoch 23/40\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0985 - accuracy: 0.9686\n",
      "Epoch 24/40\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0928 - accuracy: 0.9713\n",
      "Epoch 25/40\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0895 - accuracy: 0.9719\n",
      "Epoch 26/40\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0891 - accuracy: 0.9728\n",
      "Epoch 27/40\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0839 - accuracy: 0.9732\n",
      "Epoch 28/40\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0847 - accuracy: 0.9736\n",
      "Epoch 29/40\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0831 - accuracy: 0.9734\n",
      "Epoch 30/40\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0790 - accuracy: 0.9753\n",
      "Epoch 31/40\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0797 - accuracy: 0.9745\n",
      "Epoch 32/40\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0792 - accuracy: 0.9748\n",
      "Epoch 33/40\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0780 - accuracy: 0.9753\n",
      "Epoch 34/40\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0765 - accuracy: 0.9753\n",
      "Epoch 35/40\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.0764 - accuracy: 0.9760\n",
      "Epoch 36/40\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0750 - accuracy: 0.9761\n",
      "Epoch 37/40\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0739 - accuracy: 0.9763\n",
      "Epoch 38/40\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0754 - accuracy: 0.9762\n",
      "Epoch 39/40\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0718 - accuracy: 0.9775\n",
      "Epoch 40/40\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0685 - accuracy: 0.9786\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f37b864f978>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(np.array(train_images), train_mod_labels, epochs=40, batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model2.predict(np.array(test_images))\n",
    "pred2 = list()\n",
    "for i in range(len(y_pred)):\n",
    "    pred2.append(np.argmax(y_pred[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy and classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98       980\n",
      "           1       0.99      0.99      0.99      1135\n",
      "           2       0.98      0.96      0.97      1032\n",
      "           3       0.93      0.98      0.95      1010\n",
      "           4       0.97      0.97      0.97       982\n",
      "           5       0.95      0.95      0.95       892\n",
      "           6       0.96      0.97      0.97       958\n",
      "           7       0.97      0.97      0.97      1028\n",
      "           8       0.96      0.95      0.96       974\n",
      "           9       0.98      0.93      0.95      1009\n",
      "\n",
      "    accuracy                           0.97     10000\n",
      "   macro avg       0.97      0.97      0.97     10000\n",
      "weighted avg       0.97      0.97      0.97     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_labels, pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 966    0    1    0    0    3    5    1    3    1]\n",
      " [   0 1124    1    4    0    1    2    0    3    0]\n",
      " [   7    1  994    8    3    0    5    8    6    0]\n",
      " [   0    1    5  986    0    6    0    7    5    0]\n",
      " [   2    0    2    1  954    3    9    2    2    7]\n",
      " [   2    0    1   25    1  845    8    1    6    3]\n",
      " [   3    2    0    3    1   13  932    1    3    0]\n",
      " [   0    6    9    3    3    0    0  994    3   10]\n",
      " [   5    1    3   15    3   10    4    3  927    3]\n",
      " [   5    4    0   13   21    9    1    9    4  943]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(test_labels, pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural network with 3 hidden layers, 1 dropout layer (25% rate) and sigmoid, tanh, relu, exp activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = Sequential()\n",
    "model3.add(Dense(100, input_dim=len(train_images[0]), activation='sigmoid'))\n",
    "model3.add(Dense(100, activation='tanh'))\n",
    "model3.add(Dense(100, activation='relu'))\n",
    "model3.add(Dropout(0.25))\n",
    "model3.add(Dense(100, activation='exponential'))\n",
    "model3.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/40\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 1.0364 - accuracy: 0.6703\n",
      "Epoch 2/40\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 0.3985 - accuracy: 0.8781\n",
      "Epoch 3/40\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.3148 - accuracy: 0.9046\n",
      "Epoch 4/40\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.2726 - accuracy: 0.9173\n",
      "Epoch 5/40\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 0.2434 - accuracy: 0.9249\n",
      "Epoch 6/40\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: 0.2346 - accuracy: 0.9292\n",
      "Epoch 7/40\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.2233 - accuracy: 0.9316\n",
      "Epoch 8/40\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: 0.2136 - accuracy: 0.9336\n",
      "Epoch 9/40\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 0.1999 - accuracy: 0.9384\n",
      "Epoch 10/40\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.1863 - accuracy: 0.9414\n",
      "Epoch 11/40\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.1830 - accuracy: 0.9443\n",
      "Epoch 12/40\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.1813 - accuracy: 0.9449\n",
      "Epoch 13/40\n",
      "60000/60000 [==============================] - 1s 14us/sample - loss: 0.1705 - accuracy: 0.9472\n",
      "Epoch 14/40\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.1627 - accuracy: 0.9501\n",
      "Epoch 15/40\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.1654 - accuracy: 0.9494\n",
      "Epoch 16/40\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.1584 - accuracy: 0.9510\n",
      "Epoch 17/40\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.1538 - accuracy: 0.9529\n",
      "Epoch 18/40\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 0.1513 - accuracy: 0.9539\n",
      "Epoch 19/40\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.1509 - accuracy: 0.9547\n",
      "Epoch 20/40\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 0.1422 - accuracy: 0.9567\n",
      "Epoch 21/40\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 0.1404 - accuracy: 0.9572\n",
      "Epoch 22/40\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.1421 - accuracy: 0.9557\n",
      "Epoch 23/40\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 0.1415 - accuracy: 0.9570\n",
      "Epoch 24/40\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 0.1358 - accuracy: 0.9571\n",
      "Epoch 25/40\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.1329 - accuracy: 0.9583\n",
      "Epoch 26/40\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 0.1296 - accuracy: 0.9607\n",
      "Epoch 27/40\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.1356 - accuracy: 0.9584\n",
      "Epoch 28/40\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.1285 - accuracy: 0.9601\n",
      "Epoch 29/40\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.1348 - accuracy: 0.9578\n",
      "Epoch 30/40\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.1235 - accuracy: 0.9615\n",
      "Epoch 31/40\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.1285 - accuracy: 0.9605\n",
      "Epoch 32/40\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.1272 - accuracy: 0.9609\n",
      "Epoch 33/40\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 0.1240 - accuracy: 0.9609\n",
      "Epoch 34/40\n",
      "60000/60000 [==============================] - 1s 14us/sample - loss: 0.1202 - accuracy: 0.9624\n",
      "Epoch 35/40\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.1194 - accuracy: 0.9628\n",
      "Epoch 36/40\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 0.1136 - accuracy: 0.9643\n",
      "Epoch 37/40\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.1189 - accuracy: 0.9620\n",
      "Epoch 38/40\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 0.1238 - accuracy: 0.9617\n",
      "Epoch 39/40\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 0.1237 - accuracy: 0.9618\n",
      "Epoch 40/40\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.1183 - accuracy: 0.9634\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f37b84573c8>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.fit(np.array(train_images), train_mod_labels, epochs=40, batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model3.predict(np.array(test_images))\n",
    "pred3 = list()\n",
    "for i in range(len(y_pred)):\n",
    "    pred3.append(np.argmax(y_pred[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy and classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98       980\n",
      "           1       0.99      0.99      0.99      1135\n",
      "           2       0.96      0.96      0.96      1032\n",
      "           3       0.95      0.95      0.95      1010\n",
      "           4       0.96      0.96      0.96       982\n",
      "           5       0.95      0.94      0.95       892\n",
      "           6       0.96      0.97      0.97       958\n",
      "           7       0.97      0.97      0.97      1028\n",
      "           8       0.95      0.95      0.95       974\n",
      "           9       0.96      0.94      0.95      1009\n",
      "\n",
      "    accuracy                           0.96     10000\n",
      "   macro avg       0.96      0.96      0.96     10000\n",
      "weighted avg       0.96      0.96      0.96     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_labels, pred3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 964    0    2    2    0    6    5    1    0    0]\n",
      " [   0 1122    2    1    0    1    4    0    4    1]\n",
      " [   8    1  987   10    5    0    7    7    6    1]\n",
      " [   3    0   10  964    0    9    0    9   10    5]\n",
      " [   1    0    4    1  943    1    7    5    3   17]\n",
      " [   5    0    1   16    2  841    8    3   11    5]\n",
      " [   8    2    0    1    5    4  932    0    5    1]\n",
      " [   2    4   14    6    1    0    0  994    2    5]\n",
      " [   3    2    4   11    2   13    4    3  927    5]\n",
      " [   3    4    1    8   20    9    1    5   10  948]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(test_labels, pred3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional neural network with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adjusting input data dimesnsions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "unravelled_train_images = []\n",
    "for img in train_images:\n",
    "    unravelled_train_images.append(np.array(img).reshape(28,28,1))\n",
    "    \n",
    "unravelled_test_images = []\n",
    "for img in test_images:\n",
    "    unravelled_test_images.append(np.array(img).reshape(28,28,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = Sequential()\n",
    "model4.add(Conv2D(32, kernel_size=(3, 3), activation='relu',input_shape=(28,28,1)))\n",
    "model4.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model4.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model4.add(Dropout(0.25))\n",
    "model4.add(Flatten())\n",
    "model4.add(Dense(128, activation='relu'))\n",
    "model4.add(Dropout(0.5))\n",
    "model4.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 69s 1ms/sample - loss: 0.1538 - accuracy: 0.9637\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 61s 1ms/sample - loss: 0.0860 - accuracy: 0.9753\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 61s 1ms/sample - loss: 0.0678 - accuracy: 0.9808\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 62s 1ms/sample - loss: 0.0568 - accuracy: 0.9829\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 61s 1ms/sample - loss: 0.0519 - accuracy: 0.9848\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f377651e978>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
    "model4.fit(np.array(unravelled_train_images), train_mod_labels, epochs=5, batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model4.predict(np.array(unravelled_test_images))\n",
    "pred4 = list()\n",
    "for i in range(len(y_pred)):\n",
    "    pred4.append(np.argmax(y_pred[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy and classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       980\n",
      "           1       0.99      0.99      0.99      1135\n",
      "           2       1.00      0.98      0.99      1032\n",
      "           3       1.00      0.99      0.99      1010\n",
      "           4       0.98      1.00      0.99       982\n",
      "           5       0.98      0.99      0.99       892\n",
      "           6       0.99      0.99      0.99       958\n",
      "           7       0.98      0.99      0.99      1028\n",
      "           8       0.99      0.99      0.99       974\n",
      "           9       1.00      0.98      0.99      1009\n",
      "\n",
      "    accuracy                           0.99     10000\n",
      "   macro avg       0.99      0.99      0.99     10000\n",
      "weighted avg       0.99      0.99      0.99     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_labels, pred4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 976    1    0    0    0    0    2    1    0    0]\n",
      " [   0 1129    2    1    0    1    1    0    1    0]\n",
      " [   2    3 1010    1    4    0    1   10    1    0]\n",
      " [   0    0    1 1000    0    5    0    2    2    0]\n",
      " [   0    0    0    0  978    0    1    0    2    1]\n",
      " [   2    0    0    1    0  887    1    0    1    0]\n",
      " [   4    1    0    0    2    4  947    0    0    0]\n",
      " [   0    2    2    0    4    0    0 1019    1    0]\n",
      " [   5    0    0    0    4    0    3    1  960    1]\n",
      " [   1    3    0    1   10    5    0    4    1  984]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(test_labels, pred4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rbf kernel and C=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=2, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1 = SVC(C=2, kernel='rbf')\n",
    "clf1.fit(np.array(train_images), train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       980\n",
      "           1       0.99      0.99      0.99      1135\n",
      "           2       0.98      0.98      0.98      1032\n",
      "           3       0.98      0.99      0.98      1010\n",
      "           4       0.98      0.98      0.98       982\n",
      "           5       0.98      0.98      0.98       892\n",
      "           6       0.99      0.99      0.99       958\n",
      "           7       0.98      0.98      0.98      1028\n",
      "           8       0.98      0.98      0.98       974\n",
      "           9       0.98      0.97      0.97      1009\n",
      "\n",
      "    accuracy                           0.98     10000\n",
      "   macro avg       0.98      0.98      0.98     10000\n",
      "weighted avg       0.98      0.98      0.98     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred5 = clf1.predict(np.array(test_images))\n",
    "print(classification_report(test_labels, pred5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 973    0    1    0    0    3    0    1    2    0]\n",
      " [   0 1127    3    1    0    1    1    1    1    0]\n",
      " [   6    1 1012    0    1    0    1    7    3    1]\n",
      " [   0    0    1  997    0    3    0    4    3    2]\n",
      " [   0    0    4    0  966    0    3    0    1    8]\n",
      " [   2    0    0    6    1  876    3    0    3    1]\n",
      " [   4    2    0    0    2    3  946    0    1    0]\n",
      " [   0    5   10    2    1    0    0 1005    0    5]\n",
      " [   3    0    2    3    4    3    1    2  951    5]\n",
      " [   2    2    0    7   10    1    1    7    1  978]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(test_labels, pred5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Poly kernel and C=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=2, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='poly',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2 = SVC(C=2, kernel='poly')\n",
    "clf2.fit(np.array(train_images), train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       980\n",
      "           1       0.98      0.99      0.99      1135\n",
      "           2       0.98      0.97      0.98      1032\n",
      "           3       0.98      0.98      0.98      1010\n",
      "           4       0.98      0.98      0.98       982\n",
      "           5       0.98      0.97      0.97       892\n",
      "           6       0.98      0.98      0.98       958\n",
      "           7       0.98      0.97      0.98      1028\n",
      "           8       0.98      0.98      0.98       974\n",
      "           9       0.97      0.96      0.97      1009\n",
      "\n",
      "    accuracy                           0.98     10000\n",
      "   macro avg       0.98      0.98      0.98     10000\n",
      "weighted avg       0.98      0.98      0.98     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred6 = clf2.predict(np.array(test_images))\n",
    "print(classification_report(test_labels, pred6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 971    0    1    1    0    3    1    1    2    0]\n",
      " [   0 1128    2    1    0    0    3    0    1    0]\n",
      " [   7    3 1006    0    2    0    4    8    2    0]\n",
      " [   0    2    2  986    0    6    0    5    5    4]\n",
      " [   2    0    2    0  965    0    4    0    0    9]\n",
      " [   2    0    1    9    1  867    4    1    5    2]\n",
      " [   4    5    2    0    3    4  938    0    2    0]\n",
      " [   0   11    8    1    1    0    0  999    0    8]\n",
      " [   3    0    1    4    4    3    1    3  953    2]\n",
      " [   2    6    1    4   12    5    1    4    2  972]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(test_labels, pred6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = [\"MLP with 2 hidden layers, 1 dropout layer and relu, sigmoid, relu activations\", accuracy_score(test_labels, pred1), f1_score(test_labels, pred1, average='weighted'), precision_score(test_labels, pred1, average='weighted'), recall_score(test_labels, pred1, average='weighted')]\n",
    "l2 = [\"MLP with 2 hidden layers and sigmoid, tanh, relu activations\", accuracy_score(test_labels, pred2), f1_score(test_labels, pred2, average='weighted'), precision_score(test_labels, pred2, average='weighted'), recall_score(test_labels, pred2, average='weighted')]\n",
    "l3 = [\"MLP with 3 hidden layers, 1 dropout layer (25% rate) and sigmoid, tanh, relu, exp activations\", accuracy_score(test_labels, pred3), f1_score(test_labels, pred3, average='weighted'), precision_score(test_labels, pred3, average='weighted'), recall_score(test_labels, pred3, average='weighted')]\n",
    "l4 = [\"Convolutional neural network\", accuracy_score(test_labels, pred4), f1_score(test_labels, pred4, average='weighted'), precision_score(test_labels, pred4, average='weighted'), recall_score(test_labels, pred4, average='weighted')]\n",
    "l5 = [\"SVM with rbf kernel and C=2\", accuracy_score(test_labels, pred5), f1_score(test_labels, pred5, average='weighted'), precision_score(test_labels, pred5, average='weighted'), recall_score(test_labels, pred5, average='weighted')]\n",
    "l6 = [\"SVM with poly kernel and C=2\", accuracy_score(test_labels, pred6), f1_score(test_labels, pred6, average='weighted'), precision_score(test_labels, pred6, average='weighted'), recall_score(test_labels, pred6, average='weighted')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 score (weighted average)</th>\n",
       "      <th>Precision (weighted average)</th>\n",
       "      <th>Recall (weighted average)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLP with 2 hidden layers, 1 dropout layer and relu, sigmoid, relu activations</td>\n",
       "      <td>0.9663</td>\n",
       "      <td>0.966271</td>\n",
       "      <td>0.966388</td>\n",
       "      <td>0.9663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MLP with 2 hidden layers and sigmoid, tanh, relu activations</td>\n",
       "      <td>0.9665</td>\n",
       "      <td>0.966489</td>\n",
       "      <td>0.966698</td>\n",
       "      <td>0.9665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MLP with 3 hidden layers, 1 dropout layer (25% rate) and sigmoid, tanh, relu, exp activations</td>\n",
       "      <td>0.9622</td>\n",
       "      <td>0.962175</td>\n",
       "      <td>0.962202</td>\n",
       "      <td>0.9622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Convolutional neural network</td>\n",
       "      <td>0.9890</td>\n",
       "      <td>0.988999</td>\n",
       "      <td>0.989076</td>\n",
       "      <td>0.9890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVM with rbf kernel and C=2</td>\n",
       "      <td>0.9831</td>\n",
       "      <td>0.983092</td>\n",
       "      <td>0.983098</td>\n",
       "      <td>0.9831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVM with poly kernel and C=2</td>\n",
       "      <td>0.9785</td>\n",
       "      <td>0.978481</td>\n",
       "      <td>0.978501</td>\n",
       "      <td>0.9785</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                           Model  \\\n",
       "0                  MLP with 2 hidden layers, 1 dropout layer and relu, sigmoid, relu activations   \n",
       "1                                   MLP with 2 hidden layers and sigmoid, tanh, relu activations   \n",
       "2  MLP with 3 hidden layers, 1 dropout layer (25% rate) and sigmoid, tanh, relu, exp activations   \n",
       "3                                                                   Convolutional neural network   \n",
       "4                                                                    SVM with rbf kernel and C=2   \n",
       "5                                                                   SVM with poly kernel and C=2   \n",
       "\n",
       "   Accuracy  F1 score (weighted average)  Precision (weighted average)  \\\n",
       "0    0.9663                     0.966271                      0.966388   \n",
       "1    0.9665                     0.966489                      0.966698   \n",
       "2    0.9622                     0.962175                      0.962202   \n",
       "3    0.9890                     0.988999                      0.989076   \n",
       "4    0.9831                     0.983092                      0.983098   \n",
       "5    0.9785                     0.978481                      0.978501   \n",
       "\n",
       "   Recall (weighted average)  \n",
       "0                     0.9663  \n",
       "1                     0.9665  \n",
       "2                     0.9622  \n",
       "3                     0.9890  \n",
       "4                     0.9831  \n",
       "5                     0.9785  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [l1, l2, l3, l4, l5, l6]\n",
    "df = pd.DataFrame(data, columns = ['Model', 'Accuracy', 'F1 score (weighted average)', 'Precision (weighted average)', 'Recall (weighted average)'])\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
