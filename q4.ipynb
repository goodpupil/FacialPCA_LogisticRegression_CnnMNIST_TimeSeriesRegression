{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_array = np.genfromtxt(\"/home/virat-ub/Music/household_power_consumption.txt\", delimiter=';', skip_header=1)\n",
    "train_array = train_array[:,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting time series data to supervised learning format by window transformation  (random window selection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Window size : previous hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating training data by random window sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_samples = 50000\n",
    "counter=0\n",
    "samp_array = np.array([0]*61)\n",
    "while counter < no_of_samples:\n",
    "#     print(counter)\n",
    "    index = np.random.randint(low=0, high=len(train_array)-60-1)\n",
    "    slice_ = train_array[index:index+61]\n",
    "    if np.any(np.isnan(slice_)) == False:\n",
    "        samp_array = np.vstack((samp_array, slice_))\n",
    "        counter += 1\n",
    "samp_array = samp_array[1:,:].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train-validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(samp_array[:,:-1], samp_array[:,-1], train_size=.75)\n",
    "y_test60 = y_test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-layer perceptron using Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Two hidden layers (relu, sigmoid) and one dropout layer (25% rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(Dense(100, input_dim=60, activation='relu'))\n",
    "model1.add(Dropout(0.25))\n",
    "model1.add(Dense(100, activation='sigmoid'))\n",
    "model1.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "37500/37500 [==============================] - 1s 18us/step - loss: 0.2265 - mse: 0.2265 - mae: 0.2648\n",
      "Epoch 2/40\n",
      "37500/37500 [==============================] - 1s 16us/step - loss: 0.1135 - mse: 0.1135 - mae: 0.1796\n",
      "Epoch 3/40\n",
      "37500/37500 [==============================] - 1s 14us/step - loss: 0.1013 - mse: 0.1013 - mae: 0.1681\n",
      "Epoch 4/40\n",
      "37500/37500 [==============================] - 1s 16us/step - loss: 0.0969 - mse: 0.0969 - mae: 0.1650\n",
      "Epoch 5/40\n",
      "37500/37500 [==============================] - 1s 16us/step - loss: 0.0924 - mse: 0.0924 - mae: 0.1583\n",
      "Epoch 6/40\n",
      "37500/37500 [==============================] - 1s 14us/step - loss: 0.0893 - mse: 0.0893 - mae: 0.1545\n",
      "Epoch 7/40\n",
      "37500/37500 [==============================] - 1s 14us/step - loss: 0.0889 - mse: 0.0889 - mae: 0.1547\n",
      "Epoch 8/40\n",
      "37500/37500 [==============================] - 1s 15us/step - loss: 0.0883 - mse: 0.0883 - mae: 0.1541\n",
      "Epoch 9/40\n",
      "37500/37500 [==============================] - 1s 15us/step - loss: 0.0884 - mse: 0.0884 - mae: 0.1553\n",
      "Epoch 10/40\n",
      "37500/37500 [==============================] - 1s 14us/step - loss: 0.0859 - mse: 0.0859 - mae: 0.1505\n",
      "Epoch 11/40\n",
      "37500/37500 [==============================] - 1s 14us/step - loss: 0.0846 - mse: 0.0846 - mae: 0.1497\n",
      "Epoch 12/40\n",
      "37500/37500 [==============================] - 1s 15us/step - loss: 0.0854 - mse: 0.0854 - mae: 0.1497\n",
      "Epoch 13/40\n",
      "37500/37500 [==============================] - 1s 16us/step - loss: 0.0837 - mse: 0.0837 - mae: 0.1492\n",
      "Epoch 14/40\n",
      "37500/37500 [==============================] - 1s 15us/step - loss: 0.0833 - mse: 0.0833 - mae: 0.1495\n",
      "Epoch 15/40\n",
      "37500/37500 [==============================] - 1s 14us/step - loss: 0.0824 - mse: 0.0824 - mae: 0.1484\n",
      "Epoch 16/40\n",
      "37500/37500 [==============================] - 1s 14us/step - loss: 0.0822 - mse: 0.0822 - mae: 0.1475\n",
      "Epoch 17/40\n",
      "37500/37500 [==============================] - 1s 17us/step - loss: 0.0814 - mse: 0.0814 - mae: 0.1459\n",
      "Epoch 18/40\n",
      "37500/37500 [==============================] - 1s 14us/step - loss: 0.0810 - mse: 0.0810 - mae: 0.1475\n",
      "Epoch 19/40\n",
      "37500/37500 [==============================] - 1s 21us/step - loss: 0.0817 - mse: 0.0817 - mae: 0.1460\n",
      "Epoch 20/40\n",
      "37500/37500 [==============================] - 1s 15us/step - loss: 0.0790 - mse: 0.0790 - mae: 0.1440\n",
      "Epoch 21/40\n",
      "37500/37500 [==============================] - 1s 14us/step - loss: 0.0768 - mse: 0.0768 - mae: 0.1397\n",
      "Epoch 22/40\n",
      "37500/37500 [==============================] - 1s 14us/step - loss: 0.0782 - mse: 0.0782 - mae: 0.1435\n",
      "Epoch 23/40\n",
      "37500/37500 [==============================] - 1s 14us/step - loss: 0.0774 - mse: 0.0774 - mae: 0.1396\n",
      "Epoch 24/40\n",
      "37500/37500 [==============================] - 1s 15us/step - loss: 0.0795 - mse: 0.0795 - mae: 0.1431\n",
      "Epoch 25/40\n",
      "37500/37500 [==============================] - 1s 14us/step - loss: 0.0790 - mse: 0.0790 - mae: 0.1440\n",
      "Epoch 26/40\n",
      "37500/37500 [==============================] - 1s 13us/step - loss: 0.0779 - mse: 0.0779 - mae: 0.1401\n",
      "Epoch 27/40\n",
      "37500/37500 [==============================] - 1s 14us/step - loss: 0.0759 - mse: 0.0759 - mae: 0.1391\n",
      "Epoch 28/40\n",
      "37500/37500 [==============================] - 1s 14us/step - loss: 0.0749 - mse: 0.0749 - mae: 0.1374\n",
      "Epoch 29/40\n",
      "37500/37500 [==============================] - 0s 13us/step - loss: 0.0757 - mse: 0.0757 - mae: 0.1380\n",
      "Epoch 30/40\n",
      "37500/37500 [==============================] - 0s 13us/step - loss: 0.0765 - mse: 0.0766 - mae: 0.1375\n",
      "Epoch 31/40\n",
      "37500/37500 [==============================] - 1s 13us/step - loss: 0.0744 - mse: 0.0744 - mae: 0.1353\n",
      "Epoch 32/40\n",
      "37500/37500 [==============================] - 0s 13us/step - loss: 0.0751 - mse: 0.0751 - mae: 0.1361\n",
      "Epoch 33/40\n",
      "37500/37500 [==============================] - 1s 14us/step - loss: 0.0762 - mse: 0.0762 - mae: 0.1374\n",
      "Epoch 34/40\n",
      "37500/37500 [==============================] - 1s 14us/step - loss: 0.0766 - mse: 0.0766 - mae: 0.1395\n",
      "Epoch 35/40\n",
      "37500/37500 [==============================] - 0s 13us/step - loss: 0.0742 - mse: 0.0742 - mae: 0.1335\n",
      "Epoch 36/40\n",
      "37500/37500 [==============================] - 1s 15us/step - loss: 0.0742 - mse: 0.0742 - mae: 0.1345\n",
      "Epoch 37/40\n",
      "37500/37500 [==============================] - 1s 18us/step - loss: 0.0728 - mse: 0.0728 - mae: 0.1303\n",
      "Epoch 38/40\n",
      "37500/37500 [==============================] - 1s 17us/step - loss: 0.0751 - mse: 0.0751 - mae: 0.1353\n",
      "Epoch 39/40\n",
      "37500/37500 [==============================] - 1s 17us/step - loss: 0.0724 - mse: 0.0724 - mae: 0.1315\n",
      "Epoch 40/40\n",
      "37500/37500 [==============================] - 1s 14us/step - loss: 0.0737 - mse: 0.0737 - mae: 0.1319\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f69141b5dd8>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse','mae'])\n",
    "model1.fit(x_train, y_train, epochs=40, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = model1.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Two hidden layers (softmax, exponential) and one dropout layer (25% rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Dense(100, input_dim=60, activation='softmax'))\n",
    "model2.add(Dropout(0.25))\n",
    "model2.add(Dense(100, activation='exponential'))\n",
    "model2.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "37500/37500 [==============================] - 1s 17us/step - loss: 0.3411 - mse: 0.3411 - mae: 0.3614\n",
      "Epoch 2/40\n",
      "37500/37500 [==============================] - 1s 14us/step - loss: 0.1670 - mse: 0.1670 - mae: 0.2560\n",
      "Epoch 3/40\n",
      "37500/37500 [==============================] - 1s 14us/step - loss: 0.1483 - mse: 0.1483 - mae: 0.2455\n",
      "Epoch 4/40\n",
      "37500/37500 [==============================] - 1s 16us/step - loss: 0.1369 - mse: 0.1369 - mae: 0.2344\n",
      "Epoch 5/40\n",
      "37500/37500 [==============================] - 1s 19us/step - loss: 0.1335 - mse: 0.1335 - mae: 0.2314\n",
      "Epoch 6/40\n",
      "37500/37500 [==============================] - 1s 16us/step - loss: 0.1276 - mse: 0.1276 - mae: 0.2253\n",
      "Epoch 7/40\n",
      "37500/37500 [==============================] - 1s 14us/step - loss: 0.1227 - mse: 0.1227 - mae: 0.2204\n",
      "Epoch 8/40\n",
      "37500/37500 [==============================] - 1s 14us/step - loss: 0.1207 - mse: 0.1207 - mae: 0.2171\n",
      "Epoch 9/40\n",
      "37500/37500 [==============================] - 1s 14us/step - loss: 0.1168 - mse: 0.1168 - mae: 0.2126\n",
      "Epoch 10/40\n",
      "37500/37500 [==============================] - 1s 14us/step - loss: 0.1142 - mse: 0.1142 - mae: 0.2103\n",
      "Epoch 11/40\n",
      "37500/37500 [==============================] - 1s 14us/step - loss: 0.1123 - mse: 0.1123 - mae: 0.2078\n",
      "Epoch 12/40\n",
      "37500/37500 [==============================] - 1s 15us/step - loss: 0.1102 - mse: 0.1102 - mae: 0.2044\n",
      "Epoch 13/40\n",
      "37500/37500 [==============================] - 1s 15us/step - loss: 0.1108 - mse: 0.1108 - mae: 0.2036\n",
      "Epoch 14/40\n",
      "37500/37500 [==============================] - 1s 15us/step - loss: 0.1084 - mse: 0.1084 - mae: 0.2019\n",
      "Epoch 15/40\n",
      "37500/37500 [==============================] - 1s 19us/step - loss: 0.1087 - mse: 0.1087 - mae: 0.2005\n",
      "Epoch 16/40\n",
      "37500/37500 [==============================] - 1s 15us/step - loss: 0.1043 - mse: 0.1043 - mae: 0.1971\n",
      "Epoch 17/40\n",
      "37500/37500 [==============================] - 1s 15us/step - loss: 0.1039 - mse: 0.1039 - mae: 0.1961\n",
      "Epoch 18/40\n",
      "37500/37500 [==============================] - 1s 15us/step - loss: 0.1034 - mse: 0.1034 - mae: 0.1936\n",
      "Epoch 19/40\n",
      "37500/37500 [==============================] - 1s 14us/step - loss: 0.1016 - mse: 0.1016 - mae: 0.1931\n",
      "Epoch 20/40\n",
      "37500/37500 [==============================] - 1s 15us/step - loss: 0.1029 - mse: 0.1029 - mae: 0.1924\n",
      "Epoch 21/40\n",
      "37500/37500 [==============================] - 1s 15us/step - loss: 0.1026 - mse: 0.1026 - mae: 0.1926\n",
      "Epoch 22/40\n",
      "37500/37500 [==============================] - 1s 15us/step - loss: 0.1012 - mse: 0.1012 - mae: 0.1896\n",
      "Epoch 23/40\n",
      "37500/37500 [==============================] - 1s 14us/step - loss: 0.0985 - mse: 0.0985 - mae: 0.1876\n",
      "Epoch 24/40\n",
      "37500/37500 [==============================] - 1s 14us/step - loss: 0.0989 - mse: 0.0989 - mae: 0.1882\n",
      "Epoch 25/40\n",
      "37500/37500 [==============================] - 1s 14us/step - loss: 0.0959 - mse: 0.0959 - mae: 0.1848\n",
      "Epoch 26/40\n",
      "37500/37500 [==============================] - 1s 14us/step - loss: 0.0979 - mse: 0.0979 - mae: 0.1854\n",
      "Epoch 27/40\n",
      "37500/37500 [==============================] - 1s 15us/step - loss: 0.0969 - mse: 0.0969 - mae: 0.1834\n",
      "Epoch 28/40\n",
      "37500/37500 [==============================] - 1s 15us/step - loss: 0.0966 - mse: 0.0966 - mae: 0.1851\n",
      "Epoch 29/40\n",
      "37500/37500 [==============================] - 1s 15us/step - loss: 0.0930 - mse: 0.0930 - mae: 0.1812\n",
      "Epoch 30/40\n",
      "37500/37500 [==============================] - 1s 15us/step - loss: 0.0948 - mse: 0.0948 - mae: 0.1813\n",
      "Epoch 31/40\n",
      "37500/37500 [==============================] - 1s 15us/step - loss: 0.0939 - mse: 0.0939 - mae: 0.1812\n",
      "Epoch 32/40\n",
      "37500/37500 [==============================] - 1s 15us/step - loss: 0.0938 - mse: 0.0938 - mae: 0.1794\n",
      "Epoch 33/40\n",
      "37500/37500 [==============================] - 1s 14us/step - loss: 0.0920 - mse: 0.0920 - mae: 0.1787\n",
      "Epoch 34/40\n",
      "37500/37500 [==============================] - 1s 15us/step - loss: 0.0917 - mse: 0.0917 - mae: 0.1782\n",
      "Epoch 35/40\n",
      "37500/37500 [==============================] - 1s 15us/step - loss: 0.0929 - mse: 0.0929 - mae: 0.1771\n",
      "Epoch 36/40\n",
      "37500/37500 [==============================] - 1s 15us/step - loss: 0.0891 - mse: 0.0891 - mae: 0.1753\n",
      "Epoch 37/40\n",
      "37500/37500 [==============================] - 1s 15us/step - loss: 0.0917 - mse: 0.0917 - mae: 0.1751\n",
      "Epoch 38/40\n",
      "37500/37500 [==============================] - 1s 15us/step - loss: 0.0902 - mse: 0.0902 - mae: 0.1757\n",
      "Epoch 39/40\n",
      "37500/37500 [==============================] - 1s 15us/step - loss: 0.0882 - mse: 0.0882 - mae: 0.1716\n",
      "Epoch 40/40\n",
      "37500/37500 [==============================] - 1s 16us/step - loss: 0.0898 - mse: 0.0898 - mae: 0.1726\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f690826dcc0>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse','mae'])\n",
    "model2.fit(x_train, y_train, epochs=40, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2 = model2.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Three hidden layers (softmax, exponential, relu) and one dropout layer (25% rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = Sequential()\n",
    "model3.add(Dense(100, input_dim=60, activation='softmax'))\n",
    "model3.add(Dropout(0.25))\n",
    "model3.add(Dense(100, activation='exponential'))\n",
    "model3.add(Dense(100, activation='relu'))\n",
    "model3.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "37500/37500 [==============================] - 1s 19us/step - loss: 0.3714 - mse: 0.3714 - mae: 0.3864\n",
      "Epoch 2/40\n",
      "37500/37500 [==============================] - 1s 17us/step - loss: 0.1806 - mse: 0.1806 - mae: 0.2772\n",
      "Epoch 3/40\n",
      "37500/37500 [==============================] - 1s 16us/step - loss: 0.1517 - mse: 0.1517 - mae: 0.2511\n",
      "Epoch 4/40\n",
      "37500/37500 [==============================] - 1s 17us/step - loss: 0.1429 - mse: 0.1429 - mae: 0.2420\n",
      "Epoch 5/40\n",
      "37500/37500 [==============================] - 1s 16us/step - loss: 0.1342 - mse: 0.1342 - mae: 0.2348\n",
      "Epoch 6/40\n",
      "37500/37500 [==============================] - 1s 16us/step - loss: 0.1274 - mse: 0.1274 - mae: 0.2268\n",
      "Epoch 7/40\n",
      "37500/37500 [==============================] - 1s 16us/step - loss: 0.1210 - mse: 0.1210 - mae: 0.2188\n",
      "Epoch 8/40\n",
      "37500/37500 [==============================] - 1s 16us/step - loss: 0.1166 - mse: 0.1166 - mae: 0.2122\n",
      "Epoch 9/40\n",
      "37500/37500 [==============================] - 1s 17us/step - loss: 0.1179 - mse: 0.1179 - mae: 0.2146\n",
      "Epoch 10/40\n",
      "37500/37500 [==============================] - 1s 16us/step - loss: 0.1129 - mse: 0.1129 - mae: 0.2077\n",
      "Epoch 11/40\n",
      "37500/37500 [==============================] - 1s 16us/step - loss: 0.1098 - mse: 0.1098 - mae: 0.2035\n",
      "Epoch 12/40\n",
      "37500/37500 [==============================] - 1s 16us/step - loss: 0.1059 - mse: 0.1059 - mae: 0.1996\n",
      "Epoch 13/40\n",
      "37500/37500 [==============================] - 1s 17us/step - loss: 0.1054 - mse: 0.1054 - mae: 0.1979\n",
      "Epoch 14/40\n",
      "37500/37500 [==============================] - 1s 16us/step - loss: 0.1018 - mse: 0.1018 - mae: 0.1927\n",
      "Epoch 15/40\n",
      "37500/37500 [==============================] - 1s 16us/step - loss: 0.0987 - mse: 0.0987 - mae: 0.1868\n",
      "Epoch 16/40\n",
      "37500/37500 [==============================] - 1s 16us/step - loss: 0.1004 - mse: 0.1004 - mae: 0.1878\n",
      "Epoch 17/40\n",
      "37500/37500 [==============================] - 1s 16us/step - loss: 0.0980 - mse: 0.0980 - mae: 0.1880\n",
      "Epoch 18/40\n",
      "37500/37500 [==============================] - 1s 16us/step - loss: 0.0931 - mse: 0.0931 - mae: 0.1761\n",
      "Epoch 19/40\n",
      "37500/37500 [==============================] - 1s 17us/step - loss: 0.0911 - mse: 0.0911 - mae: 0.1751\n",
      "Epoch 20/40\n",
      "37500/37500 [==============================] - 1s 16us/step - loss: 0.0885 - mse: 0.0885 - mae: 0.1704\n",
      "Epoch 21/40\n",
      "37500/37500 [==============================] - 1s 16us/step - loss: 0.0873 - mse: 0.0873 - mae: 0.1683\n",
      "Epoch 22/40\n",
      "37500/37500 [==============================] - 1s 16us/step - loss: 0.0864 - mse: 0.0864 - mae: 0.1655\n",
      "Epoch 23/40\n",
      "37500/37500 [==============================] - 1s 16us/step - loss: 0.0848 - mse: 0.0848 - mae: 0.1635\n",
      "Epoch 24/40\n",
      "37500/37500 [==============================] - 1s 16us/step - loss: 0.0861 - mse: 0.0861 - mae: 0.1639\n",
      "Epoch 25/40\n",
      "37500/37500 [==============================] - 1s 16us/step - loss: 0.0845 - mse: 0.0845 - mae: 0.1626\n",
      "Epoch 26/40\n",
      "37500/37500 [==============================] - 1s 16us/step - loss: 0.0838 - mse: 0.0838 - mae: 0.1617\n",
      "Epoch 27/40\n",
      "37500/37500 [==============================] - 1s 16us/step - loss: 0.0807 - mse: 0.0807 - mae: 0.1539\n",
      "Epoch 28/40\n",
      "37500/37500 [==============================] - 1s 16us/step - loss: 0.0804 - mse: 0.0804 - mae: 0.1557\n",
      "Epoch 29/40\n",
      "37500/37500 [==============================] - 1s 16us/step - loss: 0.0803 - mse: 0.0803 - mae: 0.1560\n",
      "Epoch 30/40\n",
      "37500/37500 [==============================] - 1s 17us/step - loss: 0.0787 - mse: 0.0787 - mae: 0.1517\n",
      "Epoch 31/40\n",
      "37500/37500 [==============================] - 1s 16us/step - loss: 0.0782 - mse: 0.0782 - mae: 0.1485\n",
      "Epoch 32/40\n",
      "37500/37500 [==============================] - 1s 16us/step - loss: 0.0782 - mse: 0.0782 - mae: 0.1488\n",
      "Epoch 33/40\n",
      "37500/37500 [==============================] - 1s 16us/step - loss: 0.0777 - mse: 0.0777 - mae: 0.1494\n",
      "Epoch 34/40\n",
      "37500/37500 [==============================] - 1s 16us/step - loss: 0.0768 - mse: 0.0768 - mae: 0.1472\n",
      "Epoch 35/40\n",
      "37500/37500 [==============================] - 1s 16us/step - loss: 0.0767 - mse: 0.0767 - mae: 0.1474\n",
      "Epoch 36/40\n",
      "37500/37500 [==============================] - 1s 17us/step - loss: 0.0765 - mse: 0.0765 - mae: 0.1460\n",
      "Epoch 37/40\n",
      "37500/37500 [==============================] - 1s 16us/step - loss: 0.0758 - mse: 0.0758 - mae: 0.1454\n",
      "Epoch 38/40\n",
      "37500/37500 [==============================] - 1s 16us/step - loss: 0.0761 - mse: 0.0761 - mae: 0.1447\n",
      "Epoch 39/40\n",
      "37500/37500 [==============================] - 1s 16us/step - loss: 0.0771 - mse: 0.0771 - mae: 0.1470\n",
      "Epoch 40/40\n",
      "37500/37500 [==============================] - 1s 17us/step - loss: 0.0770 - mse: 0.0770 - mae: 0.1472\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f696d831198>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse','mae'])\n",
    "model3.fit(x_train, y_train, epochs=40, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred3 = model3.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sklearn's linear regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LinearRegression()\n",
    "reg.fit(x_train, y_train)\n",
    "y_pred4 = reg.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Window size : last 2 hours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating training data by random window sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_samples = 50000\n",
    "counter=0\n",
    "samp_array = np.array([0]*121)\n",
    "while counter < no_of_samples:\n",
    "#     print(counter)\n",
    "    index = np.random.randint(low=0, high=len(train_array)-120-1)\n",
    "    slice_ = train_array[index:index+121]\n",
    "    if np.any(np.isnan(slice_)) == False:\n",
    "        samp_array = np.vstack((samp_array, slice_))\n",
    "        counter += 1\n",
    "samp_array = samp_array[1:,:].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train-validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(samp_array[:,:-1], samp_array[:,-1], train_size=.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-layer perceptron using Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Two hidden layers (relu, sigmoid) and one dropout layer (25% rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model5 = Sequential()\n",
    "model5.add(Dense(100, input_dim=120, activation='relu'))\n",
    "model5.add(Dropout(0.25))\n",
    "model5.add(Dense(100, activation='sigmoid'))\n",
    "model5.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "37500/37500 [==============================] - 1s 17us/step - loss: 0.2169 - mse: 0.2169 - mae: 0.2735\n",
      "Epoch 2/40\n",
      "37500/37500 [==============================] - 1s 14us/step - loss: 0.1298 - mse: 0.1298 - mae: 0.2014\n",
      "Epoch 3/40\n",
      "37500/37500 [==============================] - 1s 16us/step - loss: 0.1182 - mse: 0.1182 - mae: 0.1905\n",
      "Epoch 4/40\n",
      "37500/37500 [==============================] - 1s 18us/step - loss: 0.1108 - mse: 0.1108 - mae: 0.1835\n",
      "Epoch 5/40\n",
      "37500/37500 [==============================] - 1s 18us/step - loss: 0.1072 - mse: 0.1072 - mae: 0.1794\n",
      "Epoch 6/40\n",
      "37500/37500 [==============================] - 1s 17us/step - loss: 0.1047 - mse: 0.1047 - mae: 0.1759\n",
      "Epoch 7/40\n",
      "37500/37500 [==============================] - 1s 16us/step - loss: 0.1009 - mse: 0.1009 - mae: 0.1713\n",
      "Epoch 8/40\n",
      "37500/37500 [==============================] - 1s 16us/step - loss: 0.0998 - mse: 0.0998 - mae: 0.1715\n",
      "Epoch 9/40\n",
      "37500/37500 [==============================] - 1s 18us/step - loss: 0.0961 - mse: 0.0961 - mae: 0.1662\n",
      "Epoch 10/40\n",
      "37500/37500 [==============================] - 1s 19us/step - loss: 0.0963 - mse: 0.0963 - mae: 0.1666\n",
      "Epoch 11/40\n",
      "37500/37500 [==============================] - 1s 16us/step - loss: 0.0965 - mse: 0.0965 - mae: 0.1679\n",
      "Epoch 12/40\n",
      "37500/37500 [==============================] - 1s 15us/step - loss: 0.0946 - mse: 0.0946 - mae: 0.1662\n",
      "Epoch 13/40\n",
      "37500/37500 [==============================] - 1s 15us/step - loss: 0.0933 - mse: 0.0933 - mae: 0.1641\n",
      "Epoch 14/40\n",
      "37500/37500 [==============================] - 1s 15us/step - loss: 0.0934 - mse: 0.0934 - mae: 0.1658\n",
      "Epoch 15/40\n",
      "37500/37500 [==============================] - 1s 15us/step - loss: 0.0937 - mse: 0.0937 - mae: 0.1647\n",
      "Epoch 16/40\n",
      "37500/37500 [==============================] - 1s 15us/step - loss: 0.0912 - mse: 0.0912 - mae: 0.1604\n",
      "Epoch 17/40\n",
      "37500/37500 [==============================] - 1s 15us/step - loss: 0.0887 - mse: 0.0887 - mae: 0.1567\n",
      "Epoch 18/40\n",
      "37500/37500 [==============================] - 1s 15us/step - loss: 0.0913 - mse: 0.0913 - mae: 0.1611\n",
      "Epoch 19/40\n",
      "37500/37500 [==============================] - 1s 15us/step - loss: 0.0883 - mse: 0.0883 - mae: 0.1554\n",
      "Epoch 20/40\n",
      "37500/37500 [==============================] - 1s 15us/step - loss: 0.0877 - mse: 0.0877 - mae: 0.1544\n",
      "Epoch 21/40\n",
      "37500/37500 [==============================] - 1s 15us/step - loss: 0.0889 - mse: 0.0889 - mae: 0.1567\n",
      "Epoch 22/40\n",
      "37500/37500 [==============================] - 1s 15us/step - loss: 0.0872 - mse: 0.0872 - mae: 0.1539\n",
      "Epoch 23/40\n",
      "37500/37500 [==============================] - 1s 15us/step - loss: 0.0859 - mse: 0.0859 - mae: 0.1530\n",
      "Epoch 24/40\n",
      "37500/37500 [==============================] - 1s 15us/step - loss: 0.0855 - mse: 0.0855 - mae: 0.1517\n",
      "Epoch 25/40\n",
      "37500/37500 [==============================] - 1s 15us/step - loss: 0.0848 - mse: 0.0848 - mae: 0.1523\n",
      "Epoch 26/40\n",
      "37500/37500 [==============================] - 1s 15us/step - loss: 0.0828 - mse: 0.0828 - mae: 0.1491\n",
      "Epoch 27/40\n",
      "37500/37500 [==============================] - 1s 15us/step - loss: 0.0854 - mse: 0.0854 - mae: 0.1518\n",
      "Epoch 28/40\n",
      "37500/37500 [==============================] - 1s 15us/step - loss: 0.0842 - mse: 0.0842 - mae: 0.1511\n",
      "Epoch 29/40\n",
      "37500/37500 [==============================] - 1s 15us/step - loss: 0.0845 - mse: 0.0845 - mae: 0.1522\n",
      "Epoch 30/40\n",
      "37500/37500 [==============================] - 1s 15us/step - loss: 0.0853 - mse: 0.0853 - mae: 0.1526\n",
      "Epoch 31/40\n",
      "37500/37500 [==============================] - 1s 15us/step - loss: 0.0839 - mse: 0.0839 - mae: 0.1508\n",
      "Epoch 32/40\n",
      "37500/37500 [==============================] - 1s 15us/step - loss: 0.0832 - mse: 0.0832 - mae: 0.1495\n",
      "Epoch 33/40\n",
      "37500/37500 [==============================] - 1s 15us/step - loss: 0.0835 - mse: 0.0835 - mae: 0.1479\n",
      "Epoch 34/40\n",
      "37500/37500 [==============================] - 1s 15us/step - loss: 0.0837 - mse: 0.0837 - mae: 0.1491\n",
      "Epoch 35/40\n",
      "37500/37500 [==============================] - 1s 15us/step - loss: 0.0831 - mse: 0.0831 - mae: 0.1485\n",
      "Epoch 36/40\n",
      "37500/37500 [==============================] - 1s 15us/step - loss: 0.0820 - mse: 0.0820 - mae: 0.1488\n",
      "Epoch 37/40\n",
      "37500/37500 [==============================] - 1s 15us/step - loss: 0.0814 - mse: 0.0814 - mae: 0.1456\n",
      "Epoch 38/40\n",
      "37500/37500 [==============================] - 1s 15us/step - loss: 0.0827 - mse: 0.0827 - mae: 0.1482\n",
      "Epoch 39/40\n",
      "37500/37500 [==============================] - 1s 15us/step - loss: 0.0810 - mse: 0.0810 - mae: 0.1450\n",
      "Epoch 40/40\n",
      "37500/37500 [==============================] - 1s 15us/step - loss: 0.0807 - mse: 0.0807 - mae: 0.1470\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f696d4ade80>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model5.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse','mae'])\n",
    "model5.fit(x_train, y_train, epochs=40, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred5 = model5.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Two hidden layers (softmax, exponential) and one dropout layer (25% rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model6 = Sequential()\n",
    "model6.add(Dense(100, input_dim=120, activation='softmax'))\n",
    "model6.add(Dropout(0.25))\n",
    "model6.add(Dense(100, activation='exponential'))\n",
    "model6.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "37500/37500 [==============================] - 1s 18us/step - loss: 0.4951 - mse: 0.4951 - mae: 0.4459\n",
      "Epoch 2/40\n",
      "37500/37500 [==============================] - 1s 18us/step - loss: 0.2168 - mse: 0.2168 - mae: 0.2983\n",
      "Epoch 3/40\n",
      "37500/37500 [==============================] - 1s 17us/step - loss: 0.1884 - mse: 0.1884 - mae: 0.2817\n",
      "Epoch 4/40\n",
      "37500/37500 [==============================] - 1s 17us/step - loss: 0.1762 - mse: 0.1762 - mae: 0.2729\n",
      "Epoch 5/40\n",
      "37500/37500 [==============================] - 1s 15us/step - loss: 0.1653 - mse: 0.1653 - mae: 0.2653\n",
      "Epoch 6/40\n",
      "37500/37500 [==============================] - 1s 15us/step - loss: 0.1580 - mse: 0.1580 - mae: 0.2586\n",
      "Epoch 7/40\n",
      "37500/37500 [==============================] - 1s 15us/step - loss: 0.1550 - mse: 0.1550 - mae: 0.2540\n",
      "Epoch 8/40\n",
      "37500/37500 [==============================] - 1s 15us/step - loss: 0.1487 - mse: 0.1487 - mae: 0.2497\n",
      "Epoch 9/40\n",
      "37500/37500 [==============================] - 1s 15us/step - loss: 0.1466 - mse: 0.1466 - mae: 0.2460\n",
      "Epoch 10/40\n",
      "37500/37500 [==============================] - 1s 16us/step - loss: 0.1431 - mse: 0.1431 - mae: 0.2429\n",
      "Epoch 11/40\n",
      "37500/37500 [==============================] - 1s 17us/step - loss: 0.1406 - mse: 0.1406 - mae: 0.2417\n",
      "Epoch 12/40\n",
      "37500/37500 [==============================] - 1s 17us/step - loss: 0.1413 - mse: 0.1413 - mae: 0.2402\n",
      "Epoch 13/40\n",
      "37500/37500 [==============================] - 1s 16us/step - loss: 0.1347 - mse: 0.1347 - mae: 0.2319\n",
      "Epoch 14/40\n",
      "37500/37500 [==============================] - 1s 19us/step - loss: 0.1325 - mse: 0.1325 - mae: 0.2317\n",
      "Epoch 15/40\n",
      "37500/37500 [==============================] - 1s 16us/step - loss: 0.1309 - mse: 0.1309 - mae: 0.2284\n",
      "Epoch 16/40\n",
      "37500/37500 [==============================] - 1s 15us/step - loss: 0.1262 - mse: 0.1262 - mae: 0.2235\n",
      "Epoch 17/40\n",
      "37500/37500 [==============================] - 1s 15us/step - loss: 0.1266 - mse: 0.1266 - mae: 0.2247\n",
      "Epoch 18/40\n",
      "37500/37500 [==============================] - 1s 16us/step - loss: 0.1261 - mse: 0.1261 - mae: 0.2227\n",
      "Epoch 19/40\n",
      "37500/37500 [==============================] - 1s 15us/step - loss: 0.1250 - mse: 0.1250 - mae: 0.2203\n",
      "Epoch 20/40\n",
      "37500/37500 [==============================] - 1s 17us/step - loss: 0.1178 - mse: 0.1178 - mae: 0.2146\n",
      "Epoch 21/40\n",
      "37500/37500 [==============================] - 1s 16us/step - loss: 0.1218 - mse: 0.1218 - mae: 0.2151\n",
      "Epoch 22/40\n",
      "37500/37500 [==============================] - 1s 19us/step - loss: 0.1187 - mse: 0.1187 - mae: 0.2135\n",
      "Epoch 23/40\n",
      "37500/37500 [==============================] - 1s 17us/step - loss: 0.1178 - mse: 0.1178 - mae: 0.2137\n",
      "Epoch 24/40\n",
      "37500/37500 [==============================] - 1s 15us/step - loss: 0.1173 - mse: 0.1173 - mae: 0.2105\n",
      "Epoch 25/40\n",
      "37500/37500 [==============================] - 1s 15us/step - loss: 0.1137 - mse: 0.1137 - mae: 0.2068\n",
      "Epoch 26/40\n",
      "37500/37500 [==============================] - 1s 15us/step - loss: 0.1124 - mse: 0.1124 - mae: 0.2056\n",
      "Epoch 27/40\n",
      "37500/37500 [==============================] - 1s 15us/step - loss: 0.1127 - mse: 0.1127 - mae: 0.2051\n",
      "Epoch 28/40\n",
      "37500/37500 [==============================] - 1s 15us/step - loss: 0.1111 - mse: 0.1111 - mae: 0.2043\n",
      "Epoch 29/40\n",
      "37500/37500 [==============================] - 1s 15us/step - loss: 0.1096 - mse: 0.1096 - mae: 0.2022\n",
      "Epoch 30/40\n",
      "37500/37500 [==============================] - 1s 15us/step - loss: 0.1077 - mse: 0.1077 - mae: 0.1987\n",
      "Epoch 31/40\n",
      "37500/37500 [==============================] - 1s 15us/step - loss: 0.1079 - mse: 0.1079 - mae: 0.1979\n",
      "Epoch 32/40\n",
      "37500/37500 [==============================] - 1s 16us/step - loss: 0.1071 - mse: 0.1071 - mae: 0.1989\n",
      "Epoch 33/40\n",
      "37500/37500 [==============================] - 1s 15us/step - loss: 0.1049 - mse: 0.1049 - mae: 0.1978\n",
      "Epoch 34/40\n",
      "37500/37500 [==============================] - 1s 17us/step - loss: 0.1070 - mse: 0.1070 - mae: 0.1968\n",
      "Epoch 35/40\n",
      "37500/37500 [==============================] - 1s 19us/step - loss: 0.1057 - mse: 0.1057 - mae: 0.1941\n",
      "Epoch 36/40\n",
      "37500/37500 [==============================] - 1s 17us/step - loss: 0.1016 - mse: 0.1016 - mae: 0.1906\n",
      "Epoch 37/40\n",
      "37500/37500 [==============================] - 1s 18us/step - loss: 0.0989 - mse: 0.0989 - mae: 0.1876\n",
      "Epoch 38/40\n",
      "37500/37500 [==============================] - 1s 20us/step - loss: 0.0986 - mse: 0.0986 - mae: 0.1871\n",
      "Epoch 39/40\n",
      "37500/37500 [==============================] - 1s 18us/step - loss: 0.1029 - mse: 0.1029 - mae: 0.1910\n",
      "Epoch 40/40\n",
      "37500/37500 [==============================] - 1s 19us/step - loss: 0.0996 - mse: 0.0996 - mae: 0.1872\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f696d848c88>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model6.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse','mae'])\n",
    "model6.fit(x_train, y_train, epochs=40, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred6 = model6.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Three hidden layers (softmax, exponential, relu) and one dropout layer (25% rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model7 = Sequential()\n",
    "model7.add(Dense(100, input_dim=120, activation='softmax'))\n",
    "model7.add(Dropout(0.25))\n",
    "model7.add(Dense(100, activation='exponential'))\n",
    "model7.add(Dense(100, activation='relu'))\n",
    "model7.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "37500/37500 [==============================] - 1s 23us/step - loss: 0.4631 - mse: 0.4631 - mae: 0.4517\n",
      "Epoch 2/40\n",
      "37500/37500 [==============================] - 1s 20us/step - loss: 0.2295 - mse: 0.2295 - mae: 0.3186\n",
      "Epoch 3/40\n",
      "37500/37500 [==============================] - 1s 17us/step - loss: 0.1991 - mse: 0.1991 - mae: 0.2968\n",
      "Epoch 4/40\n",
      "37500/37500 [==============================] - 1s 17us/step - loss: 0.1811 - mse: 0.1811 - mae: 0.2811\n",
      "Epoch 5/40\n",
      "37500/37500 [==============================] - 1s 17us/step - loss: 0.1740 - mse: 0.1740 - mae: 0.2771\n",
      "Epoch 6/40\n",
      "37500/37500 [==============================] - 1s 20us/step - loss: 0.1753 - mse: 0.1753 - mae: 0.2776\n",
      "Epoch 7/40\n",
      "37500/37500 [==============================] - 1s 19us/step - loss: 0.1667 - mse: 0.1667 - mae: 0.2690\n",
      "Epoch 8/40\n",
      "37500/37500 [==============================] - 1s 18us/step - loss: 0.1588 - mse: 0.1588 - mae: 0.2615\n",
      "Epoch 9/40\n",
      "37500/37500 [==============================] - 1s 18us/step - loss: 0.1526 - mse: 0.1526 - mae: 0.2553\n",
      "Epoch 10/40\n",
      "37500/37500 [==============================] - 1s 18us/step - loss: 0.1541 - mse: 0.1541 - mae: 0.2564\n",
      "Epoch 11/40\n",
      "37500/37500 [==============================] - 1s 18us/step - loss: 0.1475 - mse: 0.1475 - mae: 0.2473\n",
      "Epoch 12/40\n",
      "37500/37500 [==============================] - 1s 18us/step - loss: 0.1390 - mse: 0.1390 - mae: 0.2397\n",
      "Epoch 13/40\n",
      "37500/37500 [==============================] - 1s 18us/step - loss: 0.1348 - mse: 0.1348 - mae: 0.2337\n",
      "Epoch 14/40\n",
      "37500/37500 [==============================] - 1s 17us/step - loss: 0.1293 - mse: 0.1293 - mae: 0.2246\n",
      "Epoch 15/40\n",
      "37500/37500 [==============================] - 1s 17us/step - loss: 0.1282 - mse: 0.1282 - mae: 0.2246\n",
      "Epoch 16/40\n",
      "37500/37500 [==============================] - 1s 20us/step - loss: 0.1226 - mse: 0.1226 - mae: 0.2161\n",
      "Epoch 17/40\n",
      "37500/37500 [==============================] - 1s 19us/step - loss: 0.1166 - mse: 0.1166 - mae: 0.2046\n",
      "Epoch 18/40\n",
      "37500/37500 [==============================] - 1s 19us/step - loss: 0.1139 - mse: 0.1139 - mae: 0.2008\n",
      "Epoch 19/40\n",
      "37500/37500 [==============================] - 1s 18us/step - loss: 0.1083 - mse: 0.1083 - mae: 0.1922\n",
      "Epoch 20/40\n",
      "37500/37500 [==============================] - 1s 18us/step - loss: 0.1074 - mse: 0.1074 - mae: 0.1897\n",
      "Epoch 21/40\n",
      "37500/37500 [==============================] - 1s 18us/step - loss: 0.1053 - mse: 0.1053 - mae: 0.1883\n",
      "Epoch 22/40\n",
      "37500/37500 [==============================] - 1s 19us/step - loss: 0.0994 - mse: 0.0994 - mae: 0.1803\n",
      "Epoch 23/40\n",
      "37500/37500 [==============================] - 1s 17us/step - loss: 0.1001 - mse: 0.1001 - mae: 0.1786\n",
      "Epoch 24/40\n",
      "37500/37500 [==============================] - 1s 17us/step - loss: 0.0973 - mse: 0.0973 - mae: 0.1771\n",
      "Epoch 25/40\n",
      "37500/37500 [==============================] - 1s 17us/step - loss: 0.0938 - mse: 0.0938 - mae: 0.1728\n",
      "Epoch 26/40\n",
      "37500/37500 [==============================] - 1s 18us/step - loss: 0.0954 - mse: 0.0954 - mae: 0.1742\n",
      "Epoch 27/40\n",
      "37500/37500 [==============================] - 1s 17us/step - loss: 0.0924 - mse: 0.0924 - mae: 0.1685\n",
      "Epoch 28/40\n",
      "37500/37500 [==============================] - 1s 17us/step - loss: 0.0907 - mse: 0.0907 - mae: 0.1688\n",
      "Epoch 29/40\n",
      "37500/37500 [==============================] - 1s 17us/step - loss: 0.0906 - mse: 0.0906 - mae: 0.1691\n",
      "Epoch 30/40\n",
      "37500/37500 [==============================] - 1s 17us/step - loss: 0.0873 - mse: 0.0873 - mae: 0.1626\n",
      "Epoch 31/40\n",
      "37500/37500 [==============================] - 1s 17us/step - loss: 0.0903 - mse: 0.0903 - mae: 0.1667\n",
      "Epoch 32/40\n",
      "37500/37500 [==============================] - 1s 17us/step - loss: 0.0868 - mse: 0.0868 - mae: 0.1611\n",
      "Epoch 33/40\n",
      "37500/37500 [==============================] - 1s 17us/step - loss: 0.0867 - mse: 0.0867 - mae: 0.1607\n",
      "Epoch 34/40\n",
      "37500/37500 [==============================] - 1s 17us/step - loss: 0.0860 - mse: 0.0860 - mae: 0.1620\n",
      "Epoch 35/40\n",
      "37500/37500 [==============================] - 1s 17us/step - loss: 0.0846 - mse: 0.0846 - mae: 0.1569\n",
      "Epoch 36/40\n",
      "37500/37500 [==============================] - 1s 17us/step - loss: 0.0862 - mse: 0.0862 - mae: 0.1606\n",
      "Epoch 37/40\n",
      "37500/37500 [==============================] - 1s 17us/step - loss: 0.0835 - mse: 0.0835 - mae: 0.1558\n",
      "Epoch 38/40\n",
      "37500/37500 [==============================] - 1s 17us/step - loss: 0.0838 - mse: 0.0838 - mae: 0.1578\n",
      "Epoch 39/40\n",
      "37500/37500 [==============================] - 1s 17us/step - loss: 0.0834 - mse: 0.0834 - mae: 0.1559\n",
      "Epoch 40/40\n",
      "37500/37500 [==============================] - 1s 17us/step - loss: 0.0827 - mse: 0.0827 - mae: 0.1517\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f696ac38dd8>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model7.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse','mae'])\n",
    "model7.fit(x_train, y_train, epochs=40, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred7 = model7.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sklearn's linear regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LinearRegression()\n",
    "reg.fit(x_train, y_train)\n",
    "y_pred8 = reg.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1= [\"1 hour\", \"MLP with relu, sigmoid, dropout\", r2_score(y_test60, y_pred1), mean_squared_error(y_test60, y_pred1), mean_absolute_error(y_test60, y_pred1)]\n",
    "l2= [\"1 hour\", \"MLP with softmax, exponential, dropout\", r2_score(y_test60, y_pred2), mean_squared_error(y_test60, y_pred2), mean_absolute_error(y_test60, y_pred2)]\n",
    "l3= [\"1 hour\", \"MLP with softmax, exponential, relu, dropout\", r2_score(y_test60, y_pred3), mean_squared_error(y_test60, y_pred3), mean_absolute_error(y_test60, y_pred3)]\n",
    "l4= [\"1 hour\", \"Linear regressor\", r2_score(y_test60, y_pred4), mean_squared_error(y_test60, y_pred4), mean_absolute_error(y_test60, y_pred4)]\n",
    "l5= [\"2 hours\", \"MLP with relu, sigmoid, dropout\", r2_score(y_test, y_pred5), mean_squared_error(y_test, y_pred5), mean_absolute_error(y_test, y_pred5)]\n",
    "l6= [\"2 hours\", \"MLP with softmax, exponential, dropout\", r2_score(y_test, y_pred6), mean_squared_error(y_test, y_pred6), mean_absolute_error(y_test, y_pred6)]\n",
    "l7= [\"2 hours\", \"MLP with softmax, exponential, relu, dropout\", r2_score(y_test, y_pred7), mean_squared_error(y_test, y_pred7), mean_absolute_error(y_test, y_pred7)]\n",
    "l8= [\"2 hours\", \"Linear regressor\", r2_score(y_test, y_pred8), mean_squared_error(y_test, y_pred8), mean_absolute_error(y_test, y_pred8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Window size</th>\n",
       "      <th>Model</th>\n",
       "      <th>R2 score</th>\n",
       "      <th>Mean squared error</th>\n",
       "      <th>Mean absolute error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1 hour</td>\n",
       "      <td>MLP with relu, sigmoid, dropout</td>\n",
       "      <td>0.936643</td>\n",
       "      <td>0.071550</td>\n",
       "      <td>0.108776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1 hour</td>\n",
       "      <td>MLP with softmax, exponential, dropout</td>\n",
       "      <td>0.934665</td>\n",
       "      <td>0.073783</td>\n",
       "      <td>0.105019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1 hour</td>\n",
       "      <td>MLP with softmax, exponential, relu, dropout</td>\n",
       "      <td>0.929635</td>\n",
       "      <td>0.079463</td>\n",
       "      <td>0.128490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1 hour</td>\n",
       "      <td>Linear regressor</td>\n",
       "      <td>0.941252</td>\n",
       "      <td>0.066344</td>\n",
       "      <td>0.097790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2 hours</td>\n",
       "      <td>MLP with relu, sigmoid, dropout</td>\n",
       "      <td>0.932497</td>\n",
       "      <td>0.076065</td>\n",
       "      <td>0.136934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2 hours</td>\n",
       "      <td>MLP with softmax, exponential, dropout</td>\n",
       "      <td>0.934765</td>\n",
       "      <td>0.073509</td>\n",
       "      <td>0.114435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2 hours</td>\n",
       "      <td>MLP with softmax, exponential, relu, dropout</td>\n",
       "      <td>0.923816</td>\n",
       "      <td>0.085847</td>\n",
       "      <td>0.154378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2 hours</td>\n",
       "      <td>Linear regressor</td>\n",
       "      <td>0.940731</td>\n",
       "      <td>0.066786</td>\n",
       "      <td>0.100220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Window size                                         Model  R2 score  \\\n",
       "0      1 hour               MLP with relu, sigmoid, dropout  0.936643   \n",
       "1      1 hour        MLP with softmax, exponential, dropout  0.934665   \n",
       "2      1 hour  MLP with softmax, exponential, relu, dropout  0.929635   \n",
       "3      1 hour                              Linear regressor  0.941252   \n",
       "4     2 hours               MLP with relu, sigmoid, dropout  0.932497   \n",
       "5     2 hours        MLP with softmax, exponential, dropout  0.934765   \n",
       "6     2 hours  MLP with softmax, exponential, relu, dropout  0.923816   \n",
       "7     2 hours                              Linear regressor  0.940731   \n",
       "\n",
       "   Mean squared error  Mean absolute error  \n",
       "0            0.071550             0.108776  \n",
       "1            0.073783             0.105019  \n",
       "2            0.079463             0.128490  \n",
       "3            0.066344             0.097790  \n",
       "4            0.076065             0.136934  \n",
       "5            0.073509             0.114435  \n",
       "6            0.085847             0.154378  \n",
       "7            0.066786             0.100220  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [l1, l2, l3, l4, l5, l6, l7, l8]\n",
    "df = pd.DataFrame(data, columns = ['Window size', 'Model', 'R2 score', 'Mean squared error', 'Mean absolute error'])\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
